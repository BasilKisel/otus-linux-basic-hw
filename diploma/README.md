# Введение
## Контекст среды эксплуатации
## Инфраструктура web-приложения
## Операции
### Полный бакап БД
### Инкрементный бакап БД
### Восстановление БД из бакапа
### Установка вычислительного узла
# Среда администратора
## Putty
## WinSCP
## Каталоги
# Тестовый стенд
## Виртуальные машины
## Bootstrap VM
## Структура каталогов
## Инструкция по развертыванию среды


# Введение

Дипломная работа "Инфраструктура эксплуатации, отслеживания, восстановления работоспособности web-приложения в малом предприятии" по курсу Otus Linux Basic 2023-10.

В работе представлена настройка инфрастукруры для работы веб-приложения в реалиях малого предприятия.
Описано рабочее окружение администратора, настройка инструментов.
К демонстрации представлен стенд с развёрными вычислительными узлами из исходных кодов работы.

## Контекст среды эксплуатации

Данная работа предполагает небольшое предприятия в сфере производства.
Штат IT администраторов составляет не более двух человек.
Большую часть времени администраты решают проблемы пользователей внутри офисной площадки.
Деятельность по поддержанию работоспособности серверного ПО (веб-сайты, базы данных, файловые сервера) является дополнительной нагрузкой администраторов, вменённой руководством по остаточному принципу.

Разработка ПО отдана внешним подрядчикам.
Администраторы обслуживают ПО строго по инструкции от разработчиков.

## Инфраструктура web-приложения

Для упрощения разработки и внедрения, приложение должно работать в docker-контейнере.
Контейнеризация гарантирует идентичность среды выполнения.
Таким образом исключается необходимость отслеживать компоненты ОС.
Администраторы могут сменить среду эксплуатации бесшовно.
Единственной зависимостью остаётся архитектура процессоров.

В данной работе предполагается, что подрядчик подготовил веб-приложение со следующими требованиями:
* Веб приложение может быть запущено более чем в одном контейнере;
* Веб приложению требуется:
    * общий файловый каталог, разделяемый всеми запущенными экземплярами,
    * подключение к базе данных.
* Подрядчик должен предоставить dockerfile и инструкции по сборке и запуску.

Для демонстрации веб-приложения использована CMS Wordpress.
Приложение будет работать внутри докер-контейнеров на двух узлах:
* web-app-nd1 (192.168.1.15);
* web-app-nd2 (192.168.1.16).
Для администраторов предоставляется тестовая страница "http://.../hello.php" c внутренними названием и IP адресом контейнера веб-приложения.
Пример содержимого hello.php:
```
Host name: a1d3115735be
Host IP: 172.17.0.2
```
a1d3115735be - GUID докер-контейнера, 172.17.0.2 - IP адрес контейнера внутри докер-сети.
Логи работы веб-приложения записываются в каталог узла через подключенный том докер-контейнера.

Базой данных из требований Wordpress выступает MySql.
СУБД работает на узле "mysql-source" (192.168.1.13).
Для снятия бакапов развернута реплика "mysql-replica" (192.168.1.14).

Общее файловое хранилище обеспечивает NFS сервер на узле "nfs" (192.168.1.12).
К узлу подключен отказоустойчивый диск, на котором размещаются файлы приложения и бакапы БД.
NFS сервер предоставляет сетевой доступ к файлам для веб-риложения незаметно, через подключение nfs-тома к докер-контейнеру.

Распределение нагрузки между узлами веб-приложения поручено серверу nginx-rev-proxy (192.168.1.17).
Этот же сервер перенаправляет пользователей в случае отказа одного из узлов веб-приложения.

На каждом узле инфраструктуры поднят файрволл на базе IPTABLES.
Доступны только
* исходящие подключения TCP и UDP,
* все подключения внутри хоста (только 127.0.0.1),
* входящие пакеты в рамках установленных TCP сессий,
* входящие ssh, dns подключения,
* входящие TCP или UPD подключения в рамках развернутых на узле сервисов.

Для наблюдения за состоянием компонентов узлов развернут сервис Prometheus и Grafana на узле "prometheus-grafana" (192.168.1.18).
На каждый вычислительный узел установлен экспортер метрик.
На узел "nginx-rev-proxy" установлен экспортер метрик nginx.
В Grafana настроены стандартные дашборты для узлов.
Дашборд для nginx, как и экспортер метрик, предоставлен разработчиками nginx.

Для целей первичной диагностики проблем с веб-приложением установлен и настроен elk стек на узле "elk" (192.168.1.19).
На узлах "nginx-rev-proxy" (192.168.1.17), "web-app-nd1" (192.168.1.15), "web-app-nd2" (192.168.1.16) установлен filebeat - экспортер логов.

## Операции

В обязанности администраторов входит на регулярной основе проводить:
* полный логический бакап БД для восстановления данных после утери узлов СУБД;
* инкрементный логический бакап БД для точечного ручного восстановления данных;
* отслеживания нагрузки на узлы для масштабирования/обновления парка машин.

Частота сбора полного и инкрементного бакапов зависят только от Recovery Time Objective и Recovery Point Objective, выдвинутых бизнесом.

### Полный бакап БД

Полный логический бакап нужен для восстановления данных после утраты узла "mysql-source".

Полный бакап делается на узле "nfs" командой
```bash
sudo /usr/sbin/dump-mysql-serverwise.sh
```

Скрипт складывает бакап на отказоустойчивый диск в формате "tgz".
Имя файлу выбирается по схеме "all\_db\_on\_ГГГГММДД\_ЧЧммСС\_UTC.sql".
Такая схема позволяет сортировать файлы от старых к новым по имени.
Файлы полного логического бакапа сохраняются в каталог "/mnt/prod-data-drive/dbms-bcp/serverwise/".

### Инкрементный бакап БД

Инкрементный логический бакап должен выполняться чаще полного бакапа.
Он позволяет точечно найти отличия в данных и составить SQL инструкции для их восстановления.
Есть два рода ситуаций, когда инкрементный логический бакап может быть полезен для восстановления данных:
* после ошибки пользователя, удаливешего/изменившего данные;
* после полного восстановления узла mysql-source, когда нужно восстановить данные за промежуток от полного бакапа до падения СУБД.

В данной работе приведен пример инкрементного логического бакапа.
Он выполняется на сервере "nfs" командой
```bash
sudo /usr/sbin/dump-mysql-tablewise.sh
```
Скрипт создает каталог для каждой пользователькой БД, в него помещает SQL файлы с содержимым таблиц.
Файлы архивируются в формат "gz", весь каталог бакапа архивируется в формат "tar".
Архиву присваивается имя в формате "ГГГГММДД\_ЧЧммСС\_UTC.tar"
Такая схема позволяет сортировать файлы от старых к новым по имени.
Файлы инкрементного логического бакапа сохраняются в каталог "/mnt/prod-data-drive/dbms-bcp/tablewise/".

Администраторам предстоит самостоятельно реорганизовать дальнейшее хранение файлов инкрементного бакапа для минимизации потребляемого места.

### Восстановление БД из бакапа

Восстановить БД можно из любого полного логического бакапа.
Для восстановления последнего бакапа, собранного "dump-mysql-serverwise.sh", нужно запустить на узле "nfs" команду
```bash
sudo /usr/sbin/restore-mysql-serverwise.sh
```

### Установка вычислительного узла

В данной работе предполагается ручные конфигурирование и установка ПО на узлах посредством подготовленных bash скриптов.
Последовательность действий следующая:
1. Разворачивается машина с предустановленной ОС;
2. Администратор подключается к машине и копирует директорию со скриптами, файлами конфигурации, пакетами ПО;
3. Администратор выдает разрешение на выполнение скопированных bash скриптов командой `. __make_executable.sh`;
4. Администратор изменяет IP адрес и хостовое имя машины командой `sudo ./00.prepare-vm-РОЛЬ-УЗЛА.sh`;
5. Администратор устанавливает и конфигурирует ПО командой `sudo ./01.install-ПАКЕТ-ПО.sh`.

# Среда администратора

Для работы администратора, кроме обычного ПО, минимально необходимы два компонента:
* ssh клиент для подключения к узлам;
* каталог со скриптами восстановления, ПО и конфигурациями.

Для удобства администрирования в данной работе предлагаются следующие программные компоненты:
* PuTTY - уважаемый и безопасный ssh клиент для машин с ОС Windows;
* WinSCP - удобный файловый менеджер с интеграцией PuTTY.

## Putty

Для установки PuTTY нужно скачать файл-установщик с сайта "https://www.putty.org".

PuTTY подразумевает, что все настройки, вносимые в PuTTY Configuration принадлежат одному подключению.
Конфигурация производится по следующего алгоритму:
1. Загружаются настройки подключения;
2. Настройки редактируются;
3. Настройки сохраняются с тем же или новым именем подключения.

Для минимально комфортной конфигурации PuTTY нужно:
1. Выбрать Default Settings, нажать "Load";
2. Выбрать тип подключения ssh, ввести адрес или IP целевой машины;
* ![PuTTY conf 1, 2](./img/PuTTY%20Configuration_1_2.png)
3. Открыть в дереве настроек "Connection" -> "Data";
4. Ввести имя пользователя на целевой машине;
* ![PuTTY conf 3, 4](./img/PuTTY%20Configuration_3_4.png)
5. Вернуться на вкладку "Session";
6. Ввести название подключения;
7. Нажать "Save".
* ![PuTTY conf 5, 6, 7](./img/PuTTY%20Configuration_5_6_7.png)


TODO:: table of nodes

TODO:: PuTTYgen


## WinSCP
## Каталоги
# Тестовый стенд
## Виртуальные машины
## Bootstrap VM
## Структура каталогов
## Инструкция по развертыванию среды
Для развертывания среды с нуля смотри [восстановление работоспособности при утрате вычислительной инфрастуктуры](./recovery/README_disaster_recovery.md).

## bootstrap - 192.168.1.11
Чистая ВМ ubuntu 22.04 с предзагруженными пакетами.

## nfs - 192.168.1.12
Файловый сервер.
Хранит файлы веб-приложения на выделенном "неубиваемом" диске.

Директории на диске:
* ./web-app
* ./dbms-bcp

## mysql 192.168.1.13, 192.168.1.14
TODO

## web-app - 192.168.1.15, 192.168.1.16
TODO

## nginx reverse proxy - 192.168.1.17
TODO

## Prometheus + Graphana - 192.168.1.18
TODO

## ELK stack - 192.168.1.19
TODO
